import streamlit as st
from openai import OpenAI

st.set_page_config(layout="wide", page_title="ChatGPT + Notes")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'notes' not in st.session_state:
    st.session_state.notes = {}
if 'book_context' not in st.session_state:
    st.session_state.book_context = ""

DEFAULT_SYSTEM_PROMPT = """..."""

def build_prompt(user_input):
    if "ì—„ë§ˆ ì‚¬ìš©ë²•" in user_input:
        return (
            "ì´ˆë“±í•™ìƒì´ ã€Šì—„ë§ˆ ì‚¬ìš©ë²•ã€‹ì´ë¼ëŠ” ì±…ì„ ì½ì€ ë’¤ ì¹œêµ¬ì™€ í•¨ê»˜ ìì—°ìŠ¤ëŸ½ê²Œ ì£¼ê³ ë°›ì„ ìˆ˜ ìˆëŠ” ëŒ€í™”ë¥¼ ë§Œë“¤ì–´ì¤˜. "
            "..."
        )
    return user_input

# âœ… CSSë¡œ ì—¬ë°± ë° Notes ê³ ì • ì²˜ë¦¬
st.markdown("""
    <style>
    /* Chat ì˜ì—­ headerì™€ ë©”ì‹œì§€ ê°„ê²© ì œê±° */
    h1, h2, h3, h4, h5, h6 {
        margin-bottom: 0.2rem !important;
    }

    /* Chat ë©”ì‹œì§€ container ì—¬ë°± ì¤„ì´ê¸° */
    .stChatMessage {
        margin-top: 0.3rem !important;
        margin-bottom: 0.3rem !important;
        padding-top: 0.2rem !important;
        padding-bottom: 0.2rem !important;
    }

    /* ì…ë ¥ì°½ ìœ„ ì—¬ë°± ì œê±° */
    div[data-testid="chat-input"] > div:first-child {
        display: none !important;
    }

    /* ì „ì²´ ì„¹ì…˜ íŒ¨ë”© ì¡°ì • */
    section.main > div {
        padding-top: 0.5rem !important;
    }
    </style>
""", unsafe_allow_html=True)

# âœ… ë ˆì´ì•„ì›ƒ ì„¤ì •
col1, col2 = st.columns([3, 1], gap="small")

# ğŸ‘‰ Notes ì˜ì—­ (col2)
with col2:
    st.header("ğŸ“ Notes")
    uploaded = st.file_uploader("ğŸ“˜ í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ", type="txt")
    if uploaded:
        st.session_state.book_context = uploaded.read().decode("utf-8")
        st.success(" ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

    if st.session_state.messages:
        assistant_idxs = [i for i, m in enumerate(st.session_state.messages) if m['role'] == 'assistant']
        options = [f"{idx + 1}. {st.session_state.messages[idx]['content'][:30]}â€¦" for idx in assistant_idxs]
        choice = st.selectbox("ë©”ëª¨í•  ë©”ì‹œì§€ ì„ íƒ", options)
        sel_idx = assistant_idxs[options.index(choice)]
        note_text = st.session_state.notes.get(sel_idx, "")
        updated = st.text_area("ë©”ëª¨ ì…ë ¥", value=note_text, height=150)
        if st.button("ì €ì¥ ë©”ëª¨", key=f"save_{sel_idx}"):
            st.session_state.notes[sel_idx] = updated
            st.success("ë©”ëª¨ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        st.info("ì™¼ìª½ì—ì„œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")

# ğŸ‘‰ Chat ì˜ì—­ (col1)
with col1:
    st.header("ğŸ’¬ Chat")
    for idx, msg in enumerate(st.session_state.messages):
        st.chat_message(msg['role']).write(msg['content'])
        if msg['role'] == 'assistant' and idx in st.session_state.notes:
            st.markdown(
                f"<div style='margin-left:20px;color:gray;'><strong>ë©”ëª¨:</strong> {st.session_state.notes[idx]}</div>",
                unsafe_allow_html=True
            )

# âœ… ì…ë ¥ì°½ (í•­ìƒ í•˜ë‹¨)
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”â€¦")
if user_input:
    st.session_state.messages.append({'role': 'user', 'content': user_input})
    st.chat_message("user").write(user_input)

    system_prompt = DEFAULT_SYSTEM_PROMPT
    if st.session_state.book_context:
        system_prompt += "\n\n[ì¶”ê°€ ì±… ìš”ì•½]\n" + st.session_state.book_context

    with st.spinner("GPT ì‘ë‹µ ì¤‘â€¦"):
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {'role': 'system', 'content': system_prompt},
                *st.session_state.messages[:-1],
                {'role': 'user', 'content': build_prompt(user_input)}
            ]
        )
    assistant_reply = resp.choices[0].message.content
    st.session_state.messages.append({'role': 'assistant', 'content': assistant_reply})
    st.chat_message("assistant").write(assistant_reply)
